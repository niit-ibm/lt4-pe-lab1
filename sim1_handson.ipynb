{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niit-ibm/lt4-pe-lab1/blob/main/sim1_handson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTqBIB7Omd93"
      },
      "source": [
        "# LAB 1: Prompt Engineering for Project Status Updates\n",
        "## Hands-On Exercise Using IBM Granite Model via Replicate\n",
        "\n",
        "### Scenario\n",
        "You are a project intern at a mid-sized IT services company, supporting several project teams. You draft 120-word status updates for internal and external stakeholders weekly. Project leads send information in different formats, making AI-generated drafts inconsistent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t00Gj-BNmd95"
      },
      "source": [
        "## Setup: Install Required Libraries\n",
        "\n",
        "First, install the necessary libraries as used in the reference implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "743I23kvmd95"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install \"langchain_community<0.3.0\" replicate ipywidgets ibm-granite-community --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHyoRz6vmd96"
      },
      "source": [
        "## Configure Environment and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "17ZcM1y-md96"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import replicate\n",
        "from langchain_community.llms import Replicate\n",
        "from ibm_granite_community.notebook_utils import get_env_var\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SWRljomd97"
      },
      "source": [
        "## Set Replicate API Token\n",
        "\n",
        "You need a Replicate API token to use the IBM Granite model. Get your token from [replicate.com](https://replicate.com/account/api-tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gUVkPNbmd97"
      },
      "outputs": [],
      "source": [
        "# Use the utility function to get from environment or prompt\n",
        "replicate_api_token = get_env_var(\"REPLICATE_API_TOKEN\")\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = replicate_api_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZWvaF24md97"
      },
      "source": [
        "---\n",
        "## Task 1: Initialize the IBM Granite Foundation Model\n",
        "\n",
        "We'll use the **IBM Granite 3.3 8B Instruct** model via Replicate, matching the reference implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77Z9KDjrmd97"
      },
      "outputs": [],
      "source": [
        "# Model configuration - exactly as in reference\n",
        "MODEL_NAME = \"ibm-granite/granite-3.3-8b-instruct\"\n",
        "MAX_TOKENS = 1024\n",
        "TEMPERATURE = 0.2\n",
        "\n",
        "# Initialize the model\n",
        "llm = Replicate(\n",
        "    model=MODEL_NAME,\n",
        "    model_kwargs={\n",
        "        \"max_tokens\": MAX_TOKENS,\n",
        "        \"temperature\": TEMPERATURE\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"âœ… Model initialized: {MODEL_NAME}\")\n",
        "print(f\"   Max Tokens: {MAX_TOKENS}\")\n",
        "print(f\"   Temperature: {TEMPERATURE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZlI_3RZmd97"
      },
      "source": [
        "## Sample Project Input Data\n",
        "\n",
        "Here are two different formats of project updates you might receive from project leads:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqU1-2TImd98"
      },
      "outputs": [],
      "source": [
        "# Input A: Bulleted, messy, partial notes\n",
        "input_a = \"\"\"Project: Alpha CRM Upgrade â€” Weekly Update Notes\n",
        "â€¢ Login issue fixed for 80% users, pending bug #3421\n",
        "â€¢ Deployment for Phase 2 pushed from 15th to 19th\n",
        "â€¢ Client appreciated responsiveness\n",
        "â€¢ Risk: insufficient test data for UAT\n",
        "â€¢ Next steps: Dev team to finalize API changes, Testing team to complete regression\n",
        "â€¢ Need to highlight dependency on Data Engineering\n",
        "\"\"\"\n",
        "\n",
        "# Input B: Narrative-style email\n",
        "input_b = \"\"\"Forwarded message from Priya (Project Lead â€” Employee Portal Revamp)\n",
        "Here's the update you asked for â€” We completed the UI redesign for the feedback module and shared it with the client yesterday. They're happy with the look and want us to proceed. We're still waiting for HR to confirm the final list of features for Phase 2, so timelines may shift a bit. Testing is ongoing. No major blockers right now, but remind the team that the API documentation still needs review. Let's capture that as a key reminder.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Sample inputs loaded successfully!\")\n",
        "print(\"\\nYou can use 'input_a' or 'input_b' in the exercises below.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnaFyySLmd98"
      },
      "source": [
        "---\n",
        "## Task 2: Start with a Direct Prompt\n",
        "\n",
        "### Teaching Moment: Direct Prompts\n",
        "\n",
        "A ** Direct Prompt** provides minimal guidance to the model. Let's see what happens when we use a simple, direct prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxf2TH3Cmd98"
      },
      "outputs": [],
      "source": [
        "# Direct, zero-shot prompt\n",
        "zero_shot_prompt = \"Write a 120-word weekly project update.\"\n",
        "\n",
        "print(\"ðŸ”µ TASK 2: Zero-Shot Prompting\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Prompt: {zero_shot_prompt}\\n\")\n",
        "\n",
        "# Get response from model\n",
        "zero_shot_response = llm.invoke(zero_shot_prompt)\n",
        "\n",
        "print(\"Response:\")\n",
        "print(\"-\"*60)\n",
        "print(zero_shot_response)\n",
        "print(\"-\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAXHANcLmd98"
      },
      "source": [
        "### Task 2: Analysis\n",
        "\n",
        "**Observe the limitations:**\n",
        "- Output is vague and generic\n",
        "- No specific structure\n",
        "- May repeat wording from the input\n",
        "- Lacks context about the project\n",
        "\n",
        "**Conclusion:** A direct, zero-shot prompt is insufficient for generating structured, reliable project updates. We need to add more guidance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7REKvw-Omd98"
      },
      "source": [
        "---\n",
        "## Task 3: Refine to a Task-Specific Prompt with Structured Instructions\n",
        "\n",
        "Now let's add:\n",
        "- Clear task description\n",
        "- Context about the audience\n",
        "- Desired output format\n",
        "\n",
        "We'll use one of the sample inputs to make it more realistic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpbMvwv7md99"
      },
      "outputs": [],
      "source": [
        "# Task-specific prompt with structure\n",
        "def create_structured_prompt(project_input):\n",
        "    prompt = f\"\"\"Create a 120-word weekly project update for internal stakeholders.\n",
        "Include: current status, completed tasks, risks, and next steps.\n",
        "\n",
        "Based on this input:\n",
        "{project_input}\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "# Let's use Input A for this task\n",
        "structured_prompt = create_structured_prompt(input_a)\n",
        "\n",
        "print(\"ðŸŸ¢ TASK 3: Task-Specific Prompt with Structured Instructions\")\n",
        "print(\"=\"*60)\n",
        "print(\"Prompt:\")\n",
        "print(structured_prompt)\n",
        "print(\"\\nGenerating response...\\n\")\n",
        "\n",
        "# Get response from model\n",
        "structured_response = llm.invoke(structured_prompt)\n",
        "\n",
        "print(\"Response:\")\n",
        "print(\"-\"*60)\n",
        "print(structured_response)\n",
        "print(\"-\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSMH78LXmd99"
      },
      "source": [
        "### Task 3: Analysis\n",
        "\n",
        "**Improvements observed:**\n",
        "- Output becomes clearer and more focused\n",
        "- More relevant information appears\n",
        "- Better structure emerges\n",
        "\n",
        "**Remaining issues:**\n",
        "- May not match the professional tone expected\n",
        "- Format could be more consistent\n",
        "\n",
        "**Conclusion:** Task-specific prompts with structured instructions improve output quality, but we need to refine further by adding role, tone, and format specifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVK2c2bMmd99"
      },
      "source": [
        "---\n",
        "## Task 4: Refine Using Advanced Prompt Engineering Techniques\n",
        "\n",
        "Now we'll apply best practices:\n",
        "- **Role prompting**: Define who the AI is\n",
        "- **Tone specification**: Set the communication style\n",
        "- **Format constraints**: Specify exact output format\n",
        "\n",
        "This creates a comprehensive, well-engineered prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjfcZa9Gmd99"
      },
      "outputs": [],
      "source": [
        "# Advanced prompt with role, tone, and format\n",
        "def create_advanced_prompt(project_input):\n",
        "    prompt = f\"\"\"You are a project reporting assistant for an IT services company.\n",
        "\n",
        "Task: Generate a 120-word weekly project update for internal stakeholders.\n",
        "\n",
        "Tone: Concise and professional.\n",
        "\n",
        "Format: Use bullet points for the following sections:\n",
        "- Current Status\n",
        "- Completed Tasks\n",
        "- Risks/Issues\n",
        "- Next Steps\n",
        "\n",
        "Input information:\n",
        "{project_input}\n",
        "\n",
        "Generate the update now:\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "# Test with Input A\n",
        "advanced_prompt = create_advanced_prompt(input_a)\n",
        "\n",
        "print(\"ðŸŸ£ TASK 4: Advanced Prompt Engineering\")\n",
        "print(\"=\"*60)\n",
        "print(\"Prompt:\")\n",
        "print(advanced_prompt)\n",
        "print(\"\\nGenerating response...\\n\")\n",
        "\n",
        "# Get response from model\n",
        "advanced_response = llm.invoke(advanced_prompt)\n",
        "\n",
        "print(\"Response:\")\n",
        "print(\"-\"*60)\n",
        "print(advanced_response)\n",
        "print(\"-\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk7q2wxomd99"
      },
      "source": [
        "### Task 4: Analysis\n",
        "\n",
        "**Results:**\n",
        "- Highly structured output\n",
        "- Professional tone that matches workplace expectations\n",
        "- No irrelevant details or repetition\n",
        "- Consistent format across different inputs\n",
        "\n",
        "**Conclusion:** By combining task description, context, output format, role, and tone, you produce polished, stakeholder-ready project updates. This demonstrates how layering multiple prompting techniques leads to high-quality outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVVu9dSWmd99"
      },
      "source": [
        "---\n",
        "## Summary and Key Takeaways\n",
        "\n",
        "### What You Learned:\n",
        "\n",
        "1. **Zero-Shot Prompting**: Simple direct prompts produce vague, unstructured outputs\n",
        "\n",
        "2. **Structured Prompting**: Adding task description, context, and format improves clarity\n",
        "\n",
        "3. **Advanced Prompt Engineering**: Combining role, tone, and detailed format specifications produces professional, stakeholder-ready outputs\n",
        "\n",
        "\n",
        "### Best Practices:\n",
        "- Define the AI's role clearly\n",
        "- Specify desired tone and format\n",
        "- Provide context and examples\n",
        "- Structure your requirements explicitly\n",
        "\n",
        "### Technical Stack Used:\n",
        "- **Model**: IBM Granite 3.3 8B Instruct\n",
        "- **Platform**: Replicate\n",
        "- **Libraries**: langchain_community, replicate, ibm-granite-community\n",
        "- **Parameters**: Temperature=0.2, Max Tokens=1024"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}